{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fadea476-1c98-4fae-89e1-07a95bf1d88e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "from operator import itemgetter\n",
    "\n",
    "import requests\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import faiss  # For creating embeddings\n",
    "import openai  # Main model\n",
    "import PyPDF2  # For extracting text from PDFs\n",
    "from PyPDF2 import PdfReader\n",
    "from pypdf import PdfReader  # Ensure pypdf is installed\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# SQLAlchemy imports\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Text, ForeignKey\n",
    "from sqlalchemy.orm import sessionmaker, relationship, declarative_base\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# FastAPI imports\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import StreamingResponse, FileResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# LangChain core and community imports\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.tracers.log_stream import LogEntry, LogStreamCallbackHandler\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938a6ddc-16a1-4ca2-9053-5df16367513c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00286a4c-d5a5-4e37-8919-3bbb9276257a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1daba9a-ade9-44a6-92a8-fe469420ddaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf \"report_pdfs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d4c947-4cbb-41d4-a923-c3642a782e94",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "005c57c2-f7c7-4f25-b72e-99180922c14c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading PDFs: 100%|██████████| 200/200 [03:00<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All PDFs have been downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "storage_client = storage.Client()\n",
    "\n",
    "# Define your bucket name\n",
    "bucket_name = 'barchart-aichatbot'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "# Load your symbol data from the CSV (ensure this file contains a 'symbol' column)\n",
    "data = pd.read_csv(\"gs://barchart-aichatbot/Fortune_200.csv\")\n",
    "\n",
    "# Define a directory to save the downloaded PDFs\n",
    "local_dir = 'report_pdfs'\n",
    "if not os.path.exists(local_dir):\n",
    "    os.makedirs(local_dir)\n",
    "\n",
    "# Function to download a PDF file from GCS\n",
    "def download_pdf_from_gcs(bucket, symbol, pdf_file):\n",
    "    \"\"\"Download a PDF from GCS and save it locally.\"\"\"\n",
    "    # Define the local file path to save the file\n",
    "    local_file_path = os.path.join(local_dir, f\"{os.path.basename(pdf_file)}\")\n",
    "    \n",
    "    try:\n",
    "        # Access the blob in the GCS bucket\n",
    "        blob = bucket.blob(pdf_file)\n",
    "        \n",
    "        # Download the file to the local directory\n",
    "        blob.download_to_filename(local_file_path)\n",
    "        # print(f\"Downloaded {pdf_file} to {local_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {pdf_file} for {symbol}: {str(e)}\")\n",
    "\n",
    "# Iterate through the DataFrame and list all PDFs in the GCS folder for each symbol\n",
    "for index, row in tqdm(data.iterrows(), desc=\"Downloading PDFs\", total=len(data)):\n",
    "    symbol = row['Ticker Symbol']  # Get the symbol (folder name)\n",
    "    \n",
    "    # List all files within the folder 'SEC Filings/{symbol}/'\n",
    "    blobs = storage_client.list_blobs(bucket_name, prefix=f'SEC Filings/{symbol}/')\n",
    "    \n",
    "    for blob in blobs:\n",
    "        # Check if the file has a .pdf extension\n",
    "        if blob.name.endswith('.pdf'):\n",
    "            # Download the PDF from GCS\n",
    "            download_pdf_from_gcs(bucket, symbol, blob.name)\n",
    "\n",
    "print(\"All PDFs have been downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1298dd8b-e820-42e7-985c-eeb2550d10e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files: 1581\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'report_pdfs'\n",
    "\n",
    "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "print(f'Total number of files: {file_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02068890-0f44-4360-b535-d57cd38e9a59",
   "metadata": {},
   "source": [
    "### Extracting PDF Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2cda7c7-f7b8-4dd0-b910-6c53d04e58c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "local_dir = 'report_pdfs'\n",
    "\n",
    "pdf_files = [f for f in os.listdir(local_dir) if f.endswith('.pdf')]\n",
    "\n",
    "def extract_pdf_text(pdf_file):\n",
    "    try:\n",
    "        file_path = os.path.join(local_dir, pdf_file)\n",
    "        loader = PdfReader(file_path)\n",
    "        text_pages = []\n",
    "        \n",
    "        # Extract text from each page\n",
    "        for page_num in range(len(loader.pages)):\n",
    "            text_pages.append(loader.pages[page_num].extract_text())\n",
    "        \n",
    "        return text_pages\n",
    "    \n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def process_pdfs_in_batches(pdf_files, num_workers):\n",
    "    docs = []\n",
    "    total_files = len(pdf_files)\n",
    "    processed_files = 0\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(extract_pdf_text, pdf_file) for pdf_file in pdf_files]\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                docs.extend(result)\n",
    "            processed_files += 1\n",
    "            logging.info(f\"Processed {processed_files}/{total_files} files\")\n",
    "\n",
    "    return docs\n",
    "\n",
    "num_workers = 15\n",
    "docs = process_pdfs_in_batches(pdf_files, num_workers=num_workers)\n",
    "\n",
    "print(f\"Loaded {len(docs)} pages from the PDFs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ce09eb-5cbd-4fef-84d8-91f81f09ba59",
   "metadata": {},
   "source": [
    "### Chunking and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90b96b3-9907-4787-a0ef-c4c3be9ec810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 4780/4780 [00:00<00:00, 5959.61doc/s]\n",
      "2024-11-13 06:39:28,922 - Created 11,390 chunks from 4,780 pages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4780 pages and created 11390 chunks.\n"
     ]
    }
   ],
   "source": [
    "def split_documents_into_chunks(docs, chunk_size=2000, chunk_overlap=200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,    # 2000 characters per chunk\n",
    "        chunk_overlap=chunk_overlap,  # 200-character overlap\n",
    "        length_function=len\n",
    "    )\n",
    "    \n",
    "    documents = [Document(page_content=doc, metadata={}) for doc in docs]\n",
    "    \n",
    "    with tqdm(total=len(documents), desc=\"Splitting Documents\", unit=\"doc\") as pbar:\n",
    "        # Split the documents into chunks\n",
    "        doc_splits = []\n",
    "        for document in documents:\n",
    "            doc_splits.extend(text_splitter.split_documents([document]))  # Split each document\n",
    "            pbar.update(1)  # Update progress bar after each document is processed\n",
    "    \n",
    "    # Adding chunk metadata for traceability\n",
    "    for idx, split in enumerate(doc_splits):\n",
    "        split.metadata[\"chunk\"] = idx\n",
    "    \n",
    "    logging.info(f\"Created {len(doc_splits):,} chunks from {len(docs):,} pages\")\n",
    "    return doc_splits\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # num_workers = 12\n",
    "    doc_splits = split_documents_into_chunks(docs)\n",
    "    \n",
    "    # Final output\n",
    "    print(f\"Loaded {len(docs)} pages and created {len(doc_splits)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659ff51-9fd4-4f18-93a0-09691edf7722",
   "metadata": {},
   "source": [
    "### Saving Doc Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca1297a6-160d-4124-a261-e9a0a8cdf2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_splits saved to test.pkl\n",
      "Loaded 4780 pages and created 11390 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Function to save doc_splits to a file\n",
    "def save_doc_splits(doc_splits, filename='doc_splits.pkl'):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(doc_splits, f)\n",
    "    print(f\"doc_splits saved to {filename}\")\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    # Save the doc_splits to a file\n",
    "    save_doc_splits(doc_splits)\n",
    "    \n",
    "    print(f\"Loaded {len(docs)} pages and created {len(doc_splits)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea0568-0137-4a70-bd8f-be918b7314fd",
   "metadata": {},
   "source": [
    "### Loading Doc_Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa8f59e-659a-450e-b2b6-a0912dcf670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_splits loaded from doc_splits.pkl\n",
      "Loaded 518501 chunks from the file.\n"
     ]
    }
   ],
   "source": [
    "def load_doc_splits(filename='doc_splits.pkl'):\n",
    "    with open(filename, 'rb') as f:\n",
    "        doc_splits = pickle.load(f)\n",
    "    print(f\"doc_splits loaded from {filename}\")\n",
    "    return doc_splits\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    doc_splits = load_doc_splits()\n",
    "    \n",
    "    print(f\"Loaded {len(doc_splits)} chunks from the file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd07b9-93e5-470b-bf33-4d6f891754d3",
   "metadata": {},
   "source": [
    "### Creating Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5e087c-7a87-46e6-8475-a23e4906ff6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "862dfb47-3ee7-4a9f-bc7b-bd2e6b5d57b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_faiss_index(doc_splits, batch_size=25, initial_delay=10, max_retries=10, checkpoint_path=\"Checkpoint/faiss_checkpoint\", checkpoint_interval=10):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_db = None\n",
    "    indexed_docs = 0\n",
    "\n",
    "    # Check if a checkpoint exists\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        try:\n",
    "            vector_db = FAISS.load_local(checkpoint_path, embeddings, allow_dangerous_deserialization=True)\n",
    "            logging.info(f\"Loaded checkpoint from {checkpoint_path}.\")\n",
    "            indexed_docs = vector_db.index.ntotal\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to load checkpoint: {e}. Starting fresh FAISS indexing.\")\n",
    "    else:\n",
    "        logging.info(\"No checkpoint found. Starting fresh FAISS indexing.\")\n",
    "\n",
    "    start_batch = indexed_docs // batch_size\n",
    "\n",
    "    # Initialize tqdm with the remaining batches to process\n",
    "    with tqdm(total=len(doc_splits) // batch_size, initial=start_batch, desc=\"Creating Embeddings\", unit=\"batch\") as pbar:\n",
    "        for i in range(start_batch * batch_size, len(doc_splits), batch_size):\n",
    "            batch = doc_splits[i:i + batch_size]\n",
    "            retries = 0\n",
    "\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    if vector_db is None:\n",
    "                        vector_db = FAISS.from_documents(batch, embeddings)\n",
    "                    else:\n",
    "                        vector_db.add_documents(batch)\n",
    "\n",
    "                    # Save checkpoint at the defined interval\n",
    "                    if i // batch_size % checkpoint_interval == 0:\n",
    "                        vector_db.save_local(checkpoint_path)\n",
    "                        logging.info(f\"Checkpoint saved at batch {i // batch_size}\")\n",
    "\n",
    "                    # Update progress and log the number of documents indexed so far\n",
    "                    pbar.update(1)\n",
    "                    logging.info(f\"Documents indexed so far: {vector_db.index.ntotal}\")\n",
    "\n",
    "                    # Periodically collect garbage to free memory\n",
    "                    if i // batch_size % (checkpoint_interval * 2) == 0:\n",
    "                        gc.collect()\n",
    "\n",
    "                    break  # Exit retry loop if successful\n",
    "                except Exception as e:\n",
    "                    if \"429\" in str(e):\n",
    "                        wait_time = initial_delay * (2 ** retries)\n",
    "                        logging.warning(f\"Rate limit hit. Retrying in {wait_time} seconds...\")\n",
    "                        time.sleep(wait_time)\n",
    "                        retries += 1\n",
    "                    else:\n",
    "                        logging.error(f\"An error occurred: {str(e)}\")\n",
    "                        break  # Exit on non-retryable errors\n",
    "\n",
    "            if retries == max_retries:\n",
    "                raise Exception(\"Max retries exceeded. Unable to complete API requests for embeddings.\")\n",
    "\n",
    "    # Save a final checkpoint at the end\n",
    "    vector_db.save_local(checkpoint_path)\n",
    "    logging.info(\"Final checkpoint saved.\")\n",
    "    return vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5727428f-4051-487b-bd95-e9167f861523",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 00:05:11,782 - Loaded checkpoint from Checkpoint/faiss_checkpoint.\n",
      "Creating Embeddings:  99%|█████████▉| 20601/20740 [00:00<?, ?batch/s]2024-11-15 00:05:12,698 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20602/20740 [00:01<03:46,  1.64s/batch]2024-11-15 00:05:13,426 - Documents indexed so far: 515050\n",
      "2024-11-15 00:05:13,954 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20603/20740 [00:02<02:32,  1.11s/batch]2024-11-15 00:05:14,168 - Documents indexed so far: 515075\n",
      "2024-11-15 00:05:14,666 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20604/20740 [00:03<02:04,  1.10batch/s]2024-11-15 00:05:14,845 - Documents indexed so far: 515100\n",
      "2024-11-15 00:05:15,281 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20605/20740 [00:03<01:48,  1.24batch/s]2024-11-15 00:05:15,485 - Documents indexed so far: 515125\n",
      "2024-11-15 00:05:16,162 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20606/20740 [00:04<01:48,  1.23batch/s]2024-11-15 00:05:16,310 - Documents indexed so far: 515150\n",
      "2024-11-15 00:05:16,866 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20607/20740 [00:05<01:43,  1.29batch/s]2024-11-15 00:05:17,011 - Documents indexed so far: 515175\n",
      "2024-11-15 00:05:17,520 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20608/20740 [00:05<01:35,  1.38batch/s]2024-11-15 00:05:17,635 - Documents indexed so far: 515200\n",
      "2024-11-15 00:05:18,770 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20609/20740 [00:07<01:54,  1.14batch/s]2024-11-15 00:05:18,836 - Documents indexed so far: 515225\n",
      "2024-11-15 00:05:22,091 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20610/20740 [00:10<03:37,  1.67s/batch]2024-11-15 00:05:22,260 - Documents indexed so far: 515250\n",
      "2024-11-15 00:05:24,945 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:05:51,454 - Checkpoint saved at batch 20610\n",
      "Creating Embeddings:  99%|█████████▉| 20611/20740 [00:39<21:51, 10.17s/batch]2024-11-15 00:05:51,456 - Documents indexed so far: 515275\n",
      "2024-11-15 00:05:52,108 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20612/20740 [00:40<15:36,  7.32s/batch]2024-11-15 00:05:52,311 - Documents indexed so far: 515300\n",
      "2024-11-15 00:05:52,961 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20613/20740 [00:41<11:14,  5.31s/batch]2024-11-15 00:05:53,038 - Documents indexed so far: 515325\n",
      "2024-11-15 00:05:53,628 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20614/20740 [00:41<08:12,  3.91s/batch]2024-11-15 00:05:53,724 - Documents indexed so far: 515350\n",
      "2024-11-15 00:05:54,420 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20615/20740 [00:42<06:15,  3.01s/batch]2024-11-15 00:05:54,641 - Documents indexed so far: 515375\n",
      "2024-11-15 00:05:54,979 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20616/20740 [00:43<04:38,  2.25s/batch]2024-11-15 00:05:55,128 - Documents indexed so far: 515400\n",
      "2024-11-15 00:05:55,580 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20617/20740 [00:43<03:33,  1.74s/batch]2024-11-15 00:05:55,688 - Documents indexed so far: 515425\n",
      "2024-11-15 00:05:56,330 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20618/20740 [00:44<03:00,  1.48s/batch]2024-11-15 00:05:56,557 - Documents indexed so far: 515450\n",
      "2024-11-15 00:05:56,890 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20619/20740 [00:45<02:22,  1.17s/batch]2024-11-15 00:05:57,027 - Documents indexed so far: 515475\n",
      "2024-11-15 00:05:57,363 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20620/20740 [00:45<01:54,  1.05batch/s]2024-11-15 00:05:57,469 - Documents indexed so far: 515500\n",
      "2024-11-15 00:05:57,990 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:06:21,735 - Checkpoint saved at batch 20620\n",
      "Creating Embeddings:  99%|█████████▉| 20621/20740 [01:09<15:46,  7.95s/batch]2024-11-15 00:06:21,737 - Documents indexed so far: 515525\n",
      "2024-11-15 00:06:23,422 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20622/20740 [01:11<12:07,  6.16s/batch]2024-11-15 00:06:23,727 - Documents indexed so far: 515550\n",
      "2024-11-15 00:06:24,048 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20623/20740 [01:12<08:37,  4.42s/batch]2024-11-15 00:06:24,083 - Documents indexed so far: 515575\n",
      "2024-11-15 00:06:24,939 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20624/20740 [01:13<06:33,  3.39s/batch]2024-11-15 00:06:25,065 - Documents indexed so far: 515600\n",
      "2024-11-15 00:06:25,713 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20625/20740 [01:14<05:05,  2.65s/batch]2024-11-15 00:06:26,007 - Documents indexed so far: 515625\n",
      "2024-11-15 00:06:26,552 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20626/20740 [01:14<03:56,  2.08s/batch]2024-11-15 00:06:26,737 - Documents indexed so far: 515650\n",
      "2024-11-15 00:06:27,431 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20627/20740 [01:15<03:09,  1.67s/batch]2024-11-15 00:06:27,469 - Documents indexed so far: 515675\n",
      "2024-11-15 00:06:27,850 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20628/20740 [01:16<02:31,  1.36s/batch]2024-11-15 00:06:28,081 - Documents indexed so far: 515700\n",
      "2024-11-15 00:06:28,379 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20629/20740 [01:16<01:58,  1.07s/batch]2024-11-15 00:06:28,490 - Documents indexed so far: 515725\n",
      "2024-11-15 00:06:29,030 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20630/20740 [01:17<01:47,  1.02batch/s]2024-11-15 00:06:29,250 - Documents indexed so far: 515750\n",
      "2024-11-15 00:06:29,811 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:06:52,443 - Checkpoint saved at batch 20630\n",
      "Creating Embeddings:  99%|█████████▉| 20631/20740 [01:40<13:53,  7.64s/batch]2024-11-15 00:06:52,445 - Documents indexed so far: 515775\n",
      "2024-11-15 00:06:53,052 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20632/20740 [01:41<09:59,  5.55s/batch]2024-11-15 00:06:53,110 - Documents indexed so far: 515800\n",
      "2024-11-15 00:06:53,522 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20633/20740 [01:41<07:13,  4.05s/batch]2024-11-15 00:06:53,664 - Documents indexed so far: 515825\n",
      "2024-11-15 00:06:53,935 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20634/20740 [01:42<05:10,  2.93s/batch]2024-11-15 00:06:53,973 - Documents indexed so far: 515850\n",
      "2024-11-15 00:06:54,797 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20635/20740 [01:43<04:08,  2.37s/batch]2024-11-15 00:06:55,027 - Documents indexed so far: 515875\n",
      "2024-11-15 00:06:55,869 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings:  99%|█████████▉| 20636/20740 [01:44<03:24,  1.96s/batch]2024-11-15 00:06:56,045 - Documents indexed so far: 515900\n",
      "2024-11-15 00:06:56,743 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20637/20740 [01:45<02:48,  1.64s/batch]2024-11-15 00:06:56,919 - Documents indexed so far: 515925\n",
      "2024-11-15 00:06:57,636 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20638/20740 [01:46<02:25,  1.43s/batch]2024-11-15 00:06:57,865 - Documents indexed so far: 515950\n",
      "2024-11-15 00:06:58,484 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20639/20740 [01:46<02:02,  1.21s/batch]2024-11-15 00:06:58,564 - Documents indexed so far: 515975\n",
      "2024-11-15 00:06:59,208 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20640/20740 [01:47<01:49,  1.09s/batch]2024-11-15 00:06:59,390 - Documents indexed so far: 516000\n",
      "2024-11-15 00:06:59,874 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:07:25,396 - Checkpoint saved at batch 20640\n",
      "Creating Embeddings: 100%|█████████▉| 20641/20740 [02:13<14:08,  8.57s/batch]2024-11-15 00:07:25,398 - Documents indexed so far: 516025\n",
      "2024-11-15 00:07:26,904 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20642/20740 [02:15<10:37,  6.50s/batch]2024-11-15 00:07:27,087 - Documents indexed so far: 516050\n",
      "2024-11-15 00:07:27,404 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20643/20740 [02:15<07:34,  4.69s/batch]2024-11-15 00:07:27,537 - Documents indexed so far: 516075\n",
      "2024-11-15 00:07:28,201 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20644/20740 [02:16<05:38,  3.52s/batch]2024-11-15 00:07:28,347 - Documents indexed so far: 516100\n",
      "2024-11-15 00:07:28,848 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20645/20740 [02:17<04:14,  2.67s/batch]2024-11-15 00:07:29,035 - Documents indexed so far: 516125\n",
      "2024-11-15 00:07:29,803 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20646/20740 [02:18<03:18,  2.11s/batch]2024-11-15 00:07:29,845 - Documents indexed so far: 516150\n",
      "2024-11-15 00:07:30,402 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20647/20740 [02:18<02:38,  1.70s/batch]2024-11-15 00:07:30,587 - Documents indexed so far: 516175\n",
      "2024-11-15 00:07:31,159 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20648/20740 [02:19<02:10,  1.42s/batch]2024-11-15 00:07:31,334 - Documents indexed so far: 516200\n",
      "2024-11-15 00:07:31,878 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20649/20740 [02:20<01:50,  1.21s/batch]2024-11-15 00:07:32,060 - Documents indexed so far: 516225\n",
      "2024-11-15 00:07:32,537 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20650/20740 [02:20<01:30,  1.01s/batch]2024-11-15 00:07:32,598 - Documents indexed so far: 516250\n",
      "2024-11-15 00:07:33,049 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:07:57,380 - Checkpoint saved at batch 20650\n",
      "Creating Embeddings: 100%|█████████▉| 20651/20740 [02:45<12:04,  8.14s/batch]2024-11-15 00:07:57,381 - Documents indexed so far: 516275\n",
      "2024-11-15 00:07:58,049 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20652/20740 [02:46<08:42,  5.93s/batch]2024-11-15 00:07:58,165 - Documents indexed so far: 516300\n",
      "2024-11-15 00:07:58,666 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20653/20740 [02:47<06:17,  4.34s/batch]2024-11-15 00:07:58,802 - Documents indexed so far: 516325\n",
      "2024-11-15 00:07:59,145 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20654/20740 [02:47<04:34,  3.19s/batch]2024-11-15 00:07:59,290 - Documents indexed so far: 516350\n",
      "2024-11-15 00:07:59,777 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20655/20740 [02:48<03:24,  2.41s/batch]2024-11-15 00:07:59,882 - Documents indexed so far: 516375\n",
      "2024-11-15 00:08:00,193 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20656/20740 [02:48<02:32,  1.81s/batch]2024-11-15 00:08:00,300 - Documents indexed so far: 516400\n",
      "2024-11-15 00:08:00,745 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20657/20740 [02:49<02:00,  1.45s/batch]2024-11-15 00:08:00,900 - Documents indexed so far: 516425\n",
      "2024-11-15 00:08:01,448 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20658/20740 [02:49<01:37,  1.19s/batch]2024-11-15 00:08:01,496 - Documents indexed so far: 516450\n",
      "2024-11-15 00:08:01,824 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20659/20740 [02:50<01:20,  1.01batch/s]2024-11-15 00:08:02,018 - Documents indexed so far: 516475\n",
      "2024-11-15 00:08:02,542 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20660/20740 [02:50<01:10,  1.13batch/s]2024-11-15 00:08:02,657 - Documents indexed so far: 516500\n",
      "2024-11-15 00:08:03,348 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:08:30,006 - Checkpoint saved at batch 20660\n",
      "Creating Embeddings: 100%|█████████▉| 20661/20740 [03:18<11:37,  8.83s/batch]2024-11-15 00:08:30,007 - Documents indexed so far: 516525\n",
      "2024-11-15 00:08:32,885 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20662/20740 [03:21<09:15,  7.13s/batch]2024-11-15 00:08:33,177 - Documents indexed so far: 516550\n",
      "2024-11-15 00:08:34,046 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20663/20740 [03:22<06:47,  5.30s/batch]2024-11-15 00:08:34,197 - Documents indexed so far: 516575\n",
      "2024-11-15 00:08:35,013 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20664/20740 [03:23<05:04,  4.01s/batch]2024-11-15 00:08:35,205 - Documents indexed so far: 516600\n",
      "2024-11-15 00:08:35,577 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20665/20740 [03:23<03:42,  2.96s/batch]2024-11-15 00:08:35,719 - Documents indexed so far: 516625\n",
      "2024-11-15 00:08:36,496 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20666/20740 [03:24<02:54,  2.36s/batch]2024-11-15 00:08:36,691 - Documents indexed so far: 516650\n",
      "2024-11-15 00:08:37,023 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20667/20740 [03:25<02:11,  1.79s/batch]2024-11-15 00:08:37,158 - Documents indexed so far: 516675\n",
      "2024-11-15 00:08:37,545 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20668/20740 [03:25<01:41,  1.41s/batch]2024-11-15 00:08:37,658 - Documents indexed so far: 516700\n",
      "2024-11-15 00:08:38,227 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20669/20740 [03:26<01:25,  1.21s/batch]2024-11-15 00:08:38,393 - Documents indexed so far: 516725\n",
      "2024-11-15 00:08:38,914 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20670/20740 [03:27<01:12,  1.04s/batch]2024-11-15 00:08:39,039 - Documents indexed so far: 516750\n",
      "2024-11-15 00:08:39,605 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:09:07,573 - Checkpoint saved at batch 20670\n",
      "Creating Embeddings: 100%|█████████▉| 20671/20740 [03:55<10:40,  9.29s/batch]2024-11-15 00:09:07,576 - Documents indexed so far: 516775\n",
      "2024-11-15 00:09:08,340 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20672/20740 [03:56<07:40,  6.77s/batch]2024-11-15 00:09:08,467 - Documents indexed so far: 516800\n",
      "2024-11-15 00:09:08,951 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20673/20740 [03:57<05:30,  4.93s/batch]2024-11-15 00:09:09,099 - Documents indexed so far: 516825\n",
      "2024-11-15 00:09:09,518 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20674/20740 [03:57<03:56,  3.59s/batch]2024-11-15 00:09:09,554 - Documents indexed so far: 516850\n",
      "2024-11-15 00:09:09,886 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20675/20740 [03:58<02:53,  2.67s/batch]2024-11-15 00:09:10,071 - Documents indexed so far: 516875\n",
      "2024-11-15 00:09:10,486 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20676/20740 [03:58<02:08,  2.00s/batch]2024-11-15 00:09:10,523 - Documents indexed so far: 516900\n",
      "2024-11-15 00:09:10,846 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20677/20740 [03:59<01:36,  1.53s/batch]2024-11-15 00:09:10,968 - Documents indexed so far: 516925\n",
      "2024-11-15 00:09:11,621 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20678/20740 [04:00<01:22,  1.32s/batch]2024-11-15 00:09:11,800 - Documents indexed so far: 516950\n",
      "2024-11-15 00:09:12,586 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20679/20740 [04:00<01:12,  1.19s/batch]2024-11-15 00:09:12,673 - Documents indexed so far: 516975\n",
      "2024-11-15 00:09:13,124 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20680/20740 [04:01<01:00,  1.01s/batch]2024-11-15 00:09:13,258 - Documents indexed so far: 517000\n",
      "2024-11-15 00:09:13,605 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:09:36,763 - Checkpoint saved at batch 20680\n",
      "Creating Embeddings: 100%|█████████▉| 20681/20740 [04:24<07:37,  7.76s/batch]2024-11-15 00:09:36,764 - Documents indexed so far: 517025\n",
      "2024-11-15 00:09:38,729 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20682/20740 [04:27<05:53,  6.09s/batch]2024-11-15 00:09:38,962 - Documents indexed so far: 517050\n",
      "2024-11-15 00:09:39,452 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20683/20740 [04:27<04:14,  4.46s/batch]2024-11-15 00:09:39,621 - Documents indexed so far: 517075\n",
      "2024-11-15 00:09:39,944 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20684/20740 [04:28<03:02,  3.26s/batch]2024-11-15 00:09:40,085 - Documents indexed so far: 517100\n",
      "2024-11-15 00:09:40,742 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20685/20740 [04:29<02:17,  2.50s/batch]2024-11-15 00:09:40,824 - Documents indexed so far: 517125\n",
      "2024-11-15 00:09:41,285 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20686/20740 [04:29<01:44,  1.94s/batch]2024-11-15 00:09:41,458 - Documents indexed so far: 517150\n",
      "2024-11-15 00:09:42,000 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20687/20740 [04:30<01:24,  1.59s/batch]2024-11-15 00:09:42,228 - Documents indexed so far: 517175\n",
      "2024-11-15 00:09:42,809 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20688/20740 [04:31<01:08,  1.32s/batch]2024-11-15 00:09:42,928 - Documents indexed so far: 517200\n",
      "2024-11-15 00:09:43,285 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20689/20740 [04:31<00:54,  1.07s/batch]2024-11-15 00:09:43,401 - Documents indexed so far: 517225\n",
      "2024-11-15 00:09:43,874 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20690/20740 [04:32<00:45,  1.10batch/s]2024-11-15 00:09:43,948 - Documents indexed so far: 517250\n",
      "2024-11-15 00:09:44,430 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:10:06,751 - Checkpoint saved at batch 20690\n",
      "Creating Embeddings: 100%|█████████▉| 20691/20740 [04:54<06:06,  7.48s/batch]2024-11-15 00:10:06,753 - Documents indexed so far: 517275\n",
      "2024-11-15 00:10:07,124 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20692/20740 [04:55<04:17,  5.36s/batch]2024-11-15 00:10:07,182 - Documents indexed so far: 517300\n",
      "2024-11-15 00:10:07,710 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20693/20740 [04:56<03:07,  3.98s/batch]2024-11-15 00:10:07,933 - Documents indexed so far: 517325\n",
      "2024-11-15 00:10:08,570 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20694/20740 [04:56<02:19,  3.03s/batch]2024-11-15 00:10:08,757 - Documents indexed so far: 517350\n",
      "2024-11-15 00:10:09,238 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20695/20740 [04:57<01:44,  2.33s/batch]2024-11-15 00:10:09,431 - Documents indexed so far: 517375\n",
      "2024-11-15 00:10:10,114 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20696/20740 [04:58<01:22,  1.87s/batch]2024-11-15 00:10:10,223 - Documents indexed so far: 517400\n",
      "2024-11-15 00:10:10,554 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20697/20740 [04:58<01:02,  1.45s/batch]2024-11-15 00:10:10,693 - Documents indexed so far: 517425\n",
      "2024-11-15 00:10:11,152 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20698/20740 [04:59<00:49,  1.17s/batch]2024-11-15 00:10:11,229 - Documents indexed so far: 517450\n",
      "2024-11-15 00:10:11,533 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20699/20740 [04:59<00:38,  1.08batch/s]2024-11-15 00:10:11,589 - Documents indexed so far: 517475\n",
      "2024-11-15 00:10:12,375 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20700/20740 [05:00<00:38,  1.04batch/s]2024-11-15 00:10:12,615 - Documents indexed so far: 517500\n",
      "2024-11-15 00:10:13,169 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:10:38,483 - Checkpoint saved at batch 20700\n",
      "Creating Embeddings: 100%|█████████▉| 20701/20740 [05:26<05:28,  8.43s/batch]2024-11-15 00:10:38,485 - Documents indexed so far: 517525\n",
      "2024-11-15 00:10:40,193 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20702/20740 [05:28<04:05,  6.47s/batch]2024-11-15 00:10:40,380 - Documents indexed so far: 517550\n",
      "2024-11-15 00:10:41,197 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20703/20740 [05:29<02:59,  4.84s/batch]2024-11-15 00:10:41,422 - Documents indexed so far: 517575\n",
      "2024-11-15 00:10:41,925 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20704/20740 [05:30<02:09,  3.60s/batch]2024-11-15 00:10:42,130 - Documents indexed so far: 517600\n",
      "2024-11-15 00:10:45,837 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20705/20740 [05:34<02:09,  3.69s/batch]2024-11-15 00:10:46,036 - Documents indexed so far: 517625\n",
      "2024-11-15 00:10:46,816 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20706/20740 [05:35<01:37,  2.86s/batch]2024-11-15 00:10:46,963 - Documents indexed so far: 517650\n",
      "2024-11-15 00:10:47,612 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20707/20740 [05:36<01:14,  2.27s/batch]2024-11-15 00:10:47,845 - Documents indexed so far: 517675\n",
      "2024-11-15 00:10:48,392 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20708/20740 [05:36<00:57,  1.81s/batch]2024-11-15 00:10:48,581 - Documents indexed so far: 517700\n",
      "2024-11-15 00:10:49,158 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20709/20740 [05:37<00:45,  1.46s/batch]2024-11-15 00:10:49,219 - Documents indexed so far: 517725\n",
      "2024-11-15 00:10:49,890 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20710/20740 [05:38<00:37,  1.26s/batch]2024-11-15 00:10:50,027 - Documents indexed so far: 517750\n",
      "2024-11-15 00:10:50,516 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:11:14,673 - Checkpoint saved at batch 20710\n",
      "Creating Embeddings: 100%|█████████▉| 20711/20740 [06:02<04:00,  8.28s/batch]2024-11-15 00:11:14,676 - Documents indexed so far: 517775\n",
      "2024-11-15 00:11:15,069 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20712/20740 [06:03<02:46,  5.95s/batch]2024-11-15 00:11:15,178 - Documents indexed so far: 517800\n",
      "2024-11-15 00:11:15,676 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20713/20740 [06:04<01:57,  4.36s/batch]2024-11-15 00:11:15,829 - Documents indexed so far: 517825\n",
      "2024-11-15 00:11:16,161 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20714/20740 [06:04<01:23,  3.22s/batch]2024-11-15 00:11:16,393 - Documents indexed so far: 517850\n",
      "2024-11-15 00:11:17,076 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20715/20740 [06:05<01:03,  2.53s/batch]2024-11-15 00:11:17,331 - Documents indexed so far: 517875\n",
      "2024-11-15 00:11:18,075 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20716/20740 [06:06<00:49,  2.08s/batch]2024-11-15 00:11:18,354 - Documents indexed so far: 517900\n",
      "2024-11-15 00:11:19,060 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20717/20740 [06:07<00:39,  1.70s/batch]2024-11-15 00:11:19,158 - Documents indexed so far: 517925\n",
      "2024-11-15 00:11:19,957 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20718/20740 [06:08<00:31,  1.45s/batch]2024-11-15 00:11:20,041 - Documents indexed so far: 517950\n",
      "2024-11-15 00:11:20,522 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20719/20740 [06:08<00:25,  1.23s/batch]2024-11-15 00:11:20,739 - Documents indexed so far: 517975\n",
      "2024-11-15 00:11:21,228 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20720/20740 [06:09<00:21,  1.07s/batch]2024-11-15 00:11:21,449 - Documents indexed so far: 518000\n",
      "2024-11-15 00:11:21,780 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:11:47,112 - Checkpoint saved at batch 20720\n",
      "Creating Embeddings: 100%|█████████▉| 20721/20740 [06:35<02:40,  8.45s/batch]2024-11-15 00:11:47,114 - Documents indexed so far: 518025\n",
      "2024-11-15 00:11:48,537 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20722/20740 [06:36<01:54,  6.37s/batch]2024-11-15 00:11:48,640 - Documents indexed so far: 518050\n",
      "2024-11-15 00:11:49,414 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20723/20740 [06:37<01:20,  4.75s/batch]2024-11-15 00:11:49,596 - Documents indexed so far: 518075\n",
      "2024-11-15 00:11:50,242 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20724/20740 [06:38<00:57,  3.57s/batch]2024-11-15 00:11:50,410 - Documents indexed so far: 518100\n",
      "2024-11-15 00:11:51,130 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20725/20740 [06:39<00:41,  2.77s/batch]2024-11-15 00:11:51,331 - Documents indexed so far: 518125\n",
      "2024-11-15 00:11:51,916 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20726/20740 [06:40<00:30,  2.15s/batch]2024-11-15 00:11:52,029 - Documents indexed so far: 518150\n",
      "2024-11-15 00:11:52,607 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20727/20740 [06:40<00:21,  1.69s/batch]2024-11-15 00:11:52,642 - Documents indexed so far: 518175\n",
      "2024-11-15 00:11:53,478 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20728/20740 [06:41<00:17,  1.44s/batch]2024-11-15 00:11:53,513 - Documents indexed so far: 518200\n",
      "2024-11-15 00:11:53,945 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20729/20740 [06:42<00:12,  1.18s/batch]2024-11-15 00:11:54,062 - Documents indexed so far: 518225\n",
      "2024-11-15 00:11:54,765 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20730/20740 [06:43<00:10,  1.04s/batch]2024-11-15 00:11:54,800 - Documents indexed so far: 518250\n",
      "2024-11-15 00:11:55,413 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:12:19,198 - Checkpoint saved at batch 20730\n",
      "Creating Embeddings: 100%|█████████▉| 20731/20740 [07:07<01:12,  8.05s/batch]2024-11-15 00:12:19,200 - Documents indexed so far: 518275\n",
      "2024-11-15 00:12:19,779 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20732/20740 [07:08<00:47,  5.88s/batch]2024-11-15 00:12:20,018 - Documents indexed so far: 518300\n",
      "2024-11-15 00:12:20,343 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20733/20740 [07:08<00:29,  4.25s/batch]2024-11-15 00:12:20,474 - Documents indexed so far: 518325\n",
      "2024-11-15 00:12:21,042 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20734/20740 [07:09<00:19,  3.20s/batch]2024-11-15 00:12:21,203 - Documents indexed so far: 518350\n",
      "2024-11-15 00:12:21,920 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20735/20740 [07:10<00:12,  2.51s/batch]2024-11-15 00:12:22,105 - Documents indexed so far: 518375\n",
      "2024-11-15 00:12:22,619 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20736/20740 [07:10<00:07,  1.94s/batch]2024-11-15 00:12:22,735 - Documents indexed so far: 518400\n",
      "2024-11-15 00:12:23,384 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20737/20740 [07:11<00:04,  1.61s/batch]2024-11-15 00:12:23,553 - Documents indexed so far: 518425\n",
      "2024-11-15 00:12:23,931 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20738/20740 [07:12<00:02,  1.28s/batch]2024-11-15 00:12:24,086 - Documents indexed so far: 518450\n",
      "2024-11-15 00:12:24,955 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|█████████▉| 20739/20740 [07:13<00:01,  1.23s/batch]2024-11-15 00:12:25,187 - Documents indexed so far: 518475\n",
      "2024-11-15 00:12:25,892 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Creating Embeddings: 100%|██████████| 20740/20740 [07:14<00:00,  1.13s/batch]2024-11-15 00:12:26,090 - Documents indexed so far: 518500\n",
      "2024-11-15 00:12:26,258 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-15 00:12:50,834 - Checkpoint saved at batch 20740\n",
      "Creating Embeddings: 20741batch [07:39,  8.22s/batch]                        2024-11-15 00:12:50,836 - Documents indexed so far: 518501\n",
      "Creating Embeddings: 20741batch [07:40,  3.29s/batch]\n",
      "2024-11-15 00:13:15,769 - Final checkpoint saved.\n",
      "2024-11-15 00:13:15,770 - Number of documents in the FAISS index: 518501\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    batch_size = 25\n",
    "    checkpoint_path = \"Checkpoint/faiss_checkpoint\"\n",
    "\n",
    "    try:\n",
    "        vector_db = create_faiss_index(doc_splits, batch_size=batch_size, checkpoint_path=checkpoint_path)\n",
    "        \n",
    "        # Check the number of indexed documents\n",
    "        number_of_documents = vector_db.index.ntotal\n",
    "        logging.info(f\"Number of documents in the FAISS index: {number_of_documents}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to complete FAISS indexing: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3185a8-f9b9-41be-b9a8-1fdb0dd70d57",
   "metadata": {},
   "source": [
    "### Saving Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105e69b2-a9a6-4c05-aecc-ab3937adc80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 3} #k: Number of Documents to return, defaults to 4.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42194d33-b4b0-4a07-b827-789383e819cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_path = 'barchart_vectordb'\n",
    "\n",
    "vectordb_folder = vector_path\n",
    "index_name=\"faiss_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d590fe3d-8b4c-4f91-9800-8acb21fdfd7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_db.save_local(vectordb_folder, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b644ca1f-a12d-43be-b464-58555193ea1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings Created\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae2f36-2a44-4f22-911a-2f3280012c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
